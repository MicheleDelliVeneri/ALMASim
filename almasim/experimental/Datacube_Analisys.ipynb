{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourier transform plots saved for cropped_J0842 in C:\\Users\\lsann\\Desktop\\TESTPREP\\Output-test10-09\\cropped_J0842\n",
      "Fourier transform plots saved for cropped_J0842_dirty_cube in C:\\Users\\lsann\\Desktop\\TESTPREP\\Output-test10-09\\cropped_J0842_dirty_cube\n",
      "mean distance is 40.90795183044483 and std is 15.100976029316952\n",
      "Processing complete. Results saved in C:\\Users\\lsann\\Desktop\\TESTPREP\\Output-test10-09\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import kurtosis\n",
    "from numpy import hamming  # Import hamming window function\n",
    "\n",
    "# Define the directory containing the FITS files\n",
    "directory = r\"C:\\Users\\lsann\\Desktop\\TESTPREP\\Test10-09\"\n",
    "\n",
    "# Directory to save the outputs\n",
    "output_dir = r\"C:\\Users\\lsann\\Desktop\\TESTPREP\\Output-test10-09\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to calculate dynamic threshold\n",
    "def dynamic_threshold(data, sensitivity=1.0):\n",
    "    mean, std = np.mean(data), np.std(data)\n",
    "    threshold = mean + sensitivity * std\n",
    "    return threshold\n",
    "\n",
    "# Function to compute rolling mean\n",
    "def rolling_mean(data, window=75):  # Change the window size to reach the optimal plot\n",
    "    return np.convolve(data, np.ones(window) / window, mode='valid')\n",
    "\n",
    "# Function to apply hamming window\n",
    "def apply_hamming_window(data):\n",
    "    window = hamming(data.shape[0])[:, None, None] * hamming(data.shape[1])[None, :, None] * hamming(data.shape[2])[None, None, :]\n",
    "    return data * window\n",
    "\n",
    "# Function to compute and plot Fourier Transform\n",
    "def compute_and_plot_fourier_3d_full(data, title_prefix, output_dir, projection_axis='xy'):\n",
    "    # Handle NaN values by replacing them with zero\n",
    "    data = np.nan_to_num(data)\n",
    "\n",
    "    # Apply Hamming window to the data before Fourier Transform\n",
    "    data_windowed = apply_hamming_window(data)\n",
    "    \n",
    "    # Compute the Fourier transform\n",
    "    fourier_transform = np.fft.fftn(data_windowed)\n",
    "    magnitude_transform = np.abs(fourier_transform)\n",
    "    phase_transform = np.angle(fourier_transform)\n",
    "\n",
    "    # Shift the zero-frequency component to the center of the spectrum\n",
    "    magnitude_transform = np.fft.fftshift(magnitude_transform)\n",
    "    phase_transform = np.fft.fftshift(phase_transform)\n",
    "\n",
    "    # Check for empty or near-empty Fourier data to avoid blank plots\n",
    "    if np.all(magnitude_transform == 0):\n",
    "        print(f\"Warning: Fourier Transform resulted in an empty plot for {title_prefix}.\")\n",
    "        return\n",
    "\n",
    "    # Projection based on the specified axis\n",
    "    if projection_axis == 'xy':\n",
    "        magnitude_display = magnitude_transform[:, :, magnitude_transform.shape[2] // 2]\n",
    "        phase_display = phase_transform[:, :, magnitude_transform.shape[2] // 2]\n",
    "    elif projection_axis == 'xz':\n",
    "        magnitude_display = magnitude_transform[:, magnitude_transform.shape[1] // 2, :]\n",
    "        phase_display = phase_transform[:, magnitude_transform.shape[1] // 2, :]\n",
    "    elif projection_axis == 'yz':\n",
    "        magnitude_display = magnitude_transform[magnitude_transform.shape[0] // 2, :, :]\n",
    "        phase_display = phase_transform[magnitude_transform.shape[0] // 2, :, :]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid Projection Axis: {projection_axis}. Use 'xy', 'xz', or 'yz'.\")\n",
    "    \n",
    "    # Log scale for better visualization\n",
    "    magnitude_display = np.log10(magnitude_display)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(magnitude_display, cmap='gray', origin='lower')\n",
    "    plt.title(f'{title_prefix} - Magnitude')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(phase_display, cmap='hsv', origin='lower')\n",
    "    plt.title(f'{title_prefix} - Phase')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    output_path = os.path.join(output_dir, f'{title_prefix}_fourier_{projection_axis}.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Fourier transform plots saved for {title_prefix} in {output_dir}\")\n",
    "\n",
    "distances = []\n",
    "\n",
    "# Process each FITS file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".fits\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Load the data using memmap to handle large files\n",
    "        HDUL = fits.open(file_path, memmap=True)\n",
    "        data = HDUL[0].data\n",
    "\n",
    "        # Create an output directory for each target\n",
    "        target_dir = os.path.join(output_dir, os.path.splitext(filename)[0])\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir)\n",
    "\n",
    "        results_file = os.path.join(target_dir, \"results.txt\")\n",
    "\n",
    "        try:\n",
    "            # Apply Gaussian smoothing to enhance faint sources\n",
    "            smoothed_data = gaussian_filter(data, sigma=1)  # <-- Commented out\n",
    "            \n",
    "            # Integrated flux map\n",
    "            integrated_flux = np.nansum(smoothed_data, axis=0)  # Changed 'smoothed_data' to 'data'\n",
    "            total_flux = np.nansum(integrated_flux)\n",
    "\n",
    "            # Integrated cube \n",
    "            integrated_image = np.nansum(smoothed_data, axis=0)\n",
    "\n",
    "            # Center of the image\n",
    "            center_of_image = np.array([integrated_flux.shape[0] // 2, integrated_flux.shape[1] // 2])\n",
    "\n",
    "            # Exclude a larger margin around the edges to prevent detecting noise or artifacts\n",
    "            margin = 20  # Larger margin to exclude edges\n",
    "            integrated_flux[:margin, :] = 0\n",
    "            integrated_flux[-margin:, :] = 0\n",
    "            integrated_flux[:, :margin] = 0\n",
    "            integrated_flux[:, -margin:] = 0\n",
    "\n",
    "            # 90% Threshold for source detection\n",
    "            threshold = 0.99 * np.max(integrated_flux)\n",
    "\n",
    "            # Find the source coordinates (x_center, y_center) in the integrated flux map\n",
    "            y_center, x_center = np.unravel_index(np.argmax(integrated_flux > threshold), integrated_flux.shape)\n",
    "            center_of_source = np.array([y_center, x_center])\n",
    "\n",
    "            #Evaluating distance center of source - center of img\n",
    "            distance = np.sqrt((x_center - center_of_image[1])**2 + (y_center - center_of_image[0])**2)\n",
    "            distances.append(distance) \n",
    "\n",
    "            # Identify the slice that contains the maximum flux at the source coordinates\n",
    "            source_spectrum = data[:, y_center, x_center]\n",
    "            max_slice_index = np.argmax(source_spectrum)\n",
    "\n",
    "            # Extract the 2D data from this slice\n",
    "            slice_data = data[max_slice_index]\n",
    "\n",
    "            # Detect small sources: 1 to 4 pixels\n",
    "            small_source = np.sum(slice_data > threshold) <= 4\n",
    "            if small_source:\n",
    "                # Calculate source radius based on the number of pixels\n",
    "                num_pixels = np.sum(slice_data > threshold)\n",
    "                if num_pixels == 1:\n",
    "                    source_radius = 0.5  # Radius for 1 pixel flux\n",
    "                else:\n",
    "                    source_radius = 1.0  # Radius for 2-4 pixel flux\n",
    "            else:\n",
    "                # Calculate the source radius based on 90% of the maximum flux in the selected slice\n",
    "                y, x = np.indices(slice_data.shape)\n",
    "                r = np.sqrt((x - x_center)**2 + (y - y_center)**2)\n",
    "                r = r.astype(int)\n",
    "\n",
    "                tbin = np.bincount(r.ravel(), slice_data.ravel())\n",
    "                nr = np.bincount(r.ravel())\n",
    "                radialprofile = tbin / nr\n",
    "\n",
    "                radialprofile_smooth = gaussian_filter(radialprofile, sigma=2)\n",
    "                flux_threshold = 0.9 * np.max(radialprofile_smooth)\n",
    "                source_radius = np.argmax(radialprofile_smooth <= flux_threshold)\n",
    "                if source_radius == 0:\n",
    "                    source_radius = np.argmax(radialprofile_smooth > 0)\n",
    "\n",
    "            sigma_fit = source_radius / 2.0\n",
    "\n",
    "            # Adjust the mask creation based on slice_data shape\n",
    "            y, x = np.indices(slice_data.shape)\n",
    "            source_mask = (x - x_center)**2 + (y - y_center)**2 <= (3 * sigma_fit)**2\n",
    "            inner_annulus = (x - x_center)**2 + (y - y_center)**2 > (6 * sigma_fit)**2\n",
    "            outer_annulus = (x - x_center)**2 + (y - y_center)**2 <= (9 * sigma_fit)**2\n",
    "            background_mask = inner_annulus & outer_annulus\n",
    "\n",
    "            # Calculate mean source and standard deviation of background\n",
    "            mean_source = np.mean(integrated_flux[source_mask])\n",
    "            std_background = np.std(integrated_flux[background_mask])\n",
    "\n",
    "            # Calculate the SNR for the selected slice\n",
    "            overall_snr = mean_source / std_background if std_background != 0 else 0\n",
    "\n",
    "            # Calculate kurtosis of the selected slice\n",
    "            kurt = kurtosis(slice_data.ravel(), fisher=True) if slice_data.size > 0 else 0\n",
    "\n",
    "            # # Compute mean flux, std, and SNR for all slices\n",
    "            mean_fluxes = []\n",
    "            std_backgrounds = []\n",
    "            snr_values = []\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                slice_data = data[i]\n",
    "                mean_flux = np.mean(slice_data[source_mask])\n",
    "                mean_fluxes.append(mean_flux)\n",
    "                std_background = np.std(slice_data[background_mask])\n",
    "                std_backgrounds.append(std_background)\n",
    "                snr = mean_flux / std_background if std_background != 0 else 0\n",
    "                snr_values.append(snr)\n",
    "\n",
    "            # Check if SNR is NaN or 0.0, and apply zoom-in and variable threshold if needed\n",
    "            if np.isnan(overall_snr) or overall_snr == 0.0:\n",
    "                # Apply dynamic threshold\n",
    "                threshold = dynamic_threshold(integrated_flux, sensitivity=1.5)\n",
    "                y_center, x_center = np.unravel_index(np.argmax(integrated_flux > threshold), integrated_flux.shape)\n",
    "                source_spectrum = data[:, y_center, x_center]\n",
    "                max_slice_index = np.argmax(source_spectrum)\n",
    "                slice_data = data[max_slice_index]\n",
    "\n",
    "                # Recalculate source and background masks\n",
    "                y, x = np.indices(slice_data.shape)\n",
    "                r = np.sqrt((x - x_center)**2 + (y - y_center)**2)\n",
    "                source_mask = (x - x_center)**2 + (y - y_center)**2 <= (3 * sigma_fit)**2\n",
    "                inner_annulus = (x - x_center)**2 + (y - y_center)**2 > (6 * sigma_fit)**2\n",
    "                outer_annulus = (x - x_center)**2 + (y - y_center)**2 <= (9 * sigma_fit)**2\n",
    "                background_mask = inner_annulus & outer_annulus\n",
    "\n",
    "                mean_source = np.mean(integrated_flux[source_mask])\n",
    "                std_background = np.std(integrated_flux[background_mask])\n",
    "                overall_snr = mean_source / std_background if std_background != 0 else 0\n",
    "\n",
    "            # Apply rolling mean to flux, std, and snr\n",
    "            mean_flux_rolling = rolling_mean(mean_fluxes)\n",
    "            std_background_rolling = rolling_mean(std_backgrounds)\n",
    "            snr_rolling = rolling_mean(snr_values)\n",
    "\n",
    "            # Save results to the text file\n",
    "            with open(results_file, \"w\") as f:\n",
    "                f.write(f\"Name of target: {filename}\\n\")\n",
    "                f.write(f\"center_of_image: {[integrated_flux.shape[0] // 2, integrated_flux.shape[1] // 2]}\\n\")\n",
    "                f.write(f\"center_of_source: {[y_center, x_center]}\\n\")\n",
    "                f.write(f\"source_radius: {source_radius}\\n\")\n",
    "                f.write(f\"sigma_fit: {sigma_fit}\\n\")\n",
    "                f.write(f\"overall_snr: {overall_snr}\\n\")\n",
    "                f.write(f\"kurtosis: {kurt}\\n\")\n",
    "                f.write(f\"std_background: {std_background}\\n\")  # Added line\n",
    "                f.write(f\"Source flux: {np.mean(mean_source)}\\n\")\n",
    "                f.write(f\"Total flux of the cube: {total_flux}\\n\")\n",
    "                \n",
    "            # Fourier Transform\n",
    "            compute_and_plot_fourier_3d_full(data, os.path.splitext(filename)[0], target_dir, projection_axis='yz')\n",
    "            \n",
    "            # Plot rolling mean SNR\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(len(snr_rolling)), snr_rolling, label='SNR (Rolling Mean)')\n",
    "            plt.xlabel('Slice Index')\n",
    "            plt.ylabel('SNR')\n",
    "            plt.title(f'{os.path.splitext(filename)[0]} - SNR Across All Slices (Rolling Mean)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(target_dir, f'{os.path.splitext(filename)[0]}_snr_across_slices_rolling_mean.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Plot rolling mean flux\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(len(mean_flux_rolling)), mean_flux_rolling, label='Mean Flux (Rolling Mean)', color='green')\n",
    "            plt.xlabel('Slice Index')\n",
    "            plt.ylabel('Mean Flux')\n",
    "            plt.title(f'{os.path.splitext(filename)[0]} - Mean Flux Across All Slices (Rolling Mean)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(target_dir, f'{os.path.splitext(filename)[0]}_mean_flux_across_slices_rolling_mean.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Plot rolling mean std deviation\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(len(std_background_rolling)), std_background_rolling, label='Standard Deviation (Rolling Mean)', color='red')\n",
    "            plt.xlabel('Slice Index')\n",
    "            plt.ylabel('Standard Deviation')\n",
    "            plt.title(f'{os.path.splitext(filename)[0]} - Standard Deviation Across All Slices (Rolling Mean)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(target_dir, f'{os.path.splitext(filename)[0]}_std_dev_across_slices_rolling_mean.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Pixel flux distribution of the selected slice\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(slice_data.ravel(), bins=100, color='blue', alpha=0.7)\n",
    "            plt.xlabel('Pixel Flux')\n",
    "            plt.ylabel('Number of Pixels')\n",
    "            plt.title(f'{os.path.splitext(filename)[0]} - Pixel Flux Distribution of the Selected Slice')\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(target_dir, f'{os.path.splitext(filename)[0]}_pixel_flux_distribution.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Visualize the source and background regions\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(source_mask + 2 * background_mask, origin='lower', cmap='viridis')\n",
    "            plt.title(f'{os.path.splitext(filename)[0]} - Source (Green) and Background (Yellow) Regions')\n",
    "            plt.colorbar(label='Region Mask')\n",
    "            plt.savefig(os.path.join(target_dir, f'{os.path.splitext(filename)[0]}_source_and_background_regions.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Saving integrated cube plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(integrated_image, origin='lower', cmap='viridis')\n",
    "            plt.colorbar(label='Integrated Flux')\n",
    "            plt.xlabel('RA (pixel)')\n",
    "            plt.ylabel('DEC (pixel)')\n",
    "            plt.title(f'{filename} - Integrated Cube')\n",
    "            plt.savefig(os.path.join(target_dir, f'{os.path.splitext(filename)[0]}_integrated_cube.png'))\n",
    "            plt.close()\n",
    "        except MemoryError:\n",
    "            print(f\"MemoryError: Unable to process {filename} due to memory constraints.\")\n",
    "        \n",
    "        finally:\n",
    "            # Close the FITS file\n",
    "            HDUL.close()\n",
    "            \n",
    "mean_distance = np.mean(distances) if distances else 0\n",
    "std_distance = np.std(distances)\n",
    "print(f'mean distance is {mean_distance} and std is {std_distance}')\n",
    "\n",
    "print(f\"Processing complete. Results saved in {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
