{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "import tempfile\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "from casatasks import simobserve, tclean, exportfits\n",
    "import os\n",
    "import shutil\n",
    "from casatools import table\n",
    "from astropy.constants import c\n",
    "from astropy.time import Time\n",
    "import astropy.units as U\n",
    "from martini.sources import TNGSource\n",
    "from martini import DataCube, Martini\n",
    "from martini.beams import GaussianBeam\n",
    "from martini.noise import GaussianNoise\n",
    "from martini.spectral_models import GaussianSpectrum\n",
    "from martini.sph_kernels import AdaptiveKernel, GaussianKernel, CubicSplineKernel, DiracDeltaKernel\n",
    "from natsort import natsorted\n",
    "import math\n",
    "from math import pi\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from time import strftime, gmtime\n",
    "import dask\n",
    "from typing import Optional\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "from random import choices\n",
    "import simulator as sim\n",
    "\n",
    "from spectral_cube import SpectralCube\n",
    "import h5py\n",
    "os.environ['MPLCONFIGDIR'] = temp_dir.name\n",
    "pd.options.mode.chained_assignment = None  \n",
    "def get_data_from_hdf(file):\n",
    "    data = list()\n",
    "    column_names = list()\n",
    "    r = h5py.File(file, 'r')\n",
    "    for key in r.keys():\n",
    "        if key == 'Snapshot_99':\n",
    "            group = r[key]\n",
    "            for key2 in group.keys():\n",
    "                column_names.append(key2)\n",
    "                data.append(group[key2])\n",
    "    values = np.array(data)\n",
    "    db = pd.DataFrame(values.T, columns=column_names)     \n",
    "    return db   \n",
    "\n",
    "def load_fits(inFile):\n",
    "    hdu_list = fits.open(inFile)\n",
    "    data = hdu_list[0].data\n",
    "    header = hdu_list[0].header\n",
    "    hdu_list.close()\n",
    "    return data, header\n",
    "\n",
    "def write_datacube_to_fits(\n",
    "    datacube,\n",
    "    filename,\n",
    "    channels=\"frequency\",\n",
    "    overwrite=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Output the DataCube to a FITS-format file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : string\n",
    "            Name of the file to write. '.fits' will be appended if not already\n",
    "            present.\n",
    "\n",
    "        channels : {'frequency', 'velocity'}, optional\n",
    "            Type of units used along the spectral axis in output file.\n",
    "            (Default: 'frequency'.)\n",
    "\n",
    "        overwrite: bool, optional\n",
    "            Whether to allow overwriting existing files. (Default: True.)\n",
    "        \"\"\"\n",
    "\n",
    "        datacube.drop_pad()\n",
    "        if channels == \"frequency\":\n",
    "            datacube.freq_channels()\n",
    "        elif channels == \"velocity\":\n",
    "            datacube.velocity_channels()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Unknown 'channels' value \"\n",
    "                \"(use 'frequency' or 'velocity'.\"\n",
    "            )\n",
    "\n",
    "        filename = filename if filename[-5:] == \".fits\" else filename + \".fits\"\n",
    "\n",
    "        wcs_header = datacube.wcs.to_header()\n",
    "        wcs_header.rename_keyword(\"WCSAXES\", \"NAXIS\")\n",
    "\n",
    "        header = fits.Header()\n",
    "        header.append((\"SIMPLE\", \"T\"))\n",
    "        header.append((\"BITPIX\", 16))\n",
    "        header.append((\"NAXIS\", wcs_header[\"NAXIS\"]))\n",
    "        header.append((\"NAXIS1\", datacube.n_px_x))\n",
    "        header.append((\"NAXIS2\", datacube.n_px_y))\n",
    "        header.append((\"NAXIS3\", datacube.n_channels))\n",
    "        header.append((\"NAXIS4\", 1))\n",
    "        header.append((\"EXTEND\", \"T\"))\n",
    "        header.append((\"CDELT1\", wcs_header[\"CDELT1\"]))\n",
    "        header.append((\"CRPIX1\", wcs_header[\"CRPIX1\"]))\n",
    "        header.append((\"CRVAL1\", wcs_header[\"CRVAL1\"]))\n",
    "        header.append((\"CTYPE1\", wcs_header[\"CTYPE1\"]))\n",
    "        header.append((\"CUNIT1\", wcs_header[\"CUNIT1\"]))\n",
    "        header.append((\"CDELT2\", wcs_header[\"CDELT2\"]))\n",
    "        header.append((\"CRPIX2\", wcs_header[\"CRPIX2\"]))\n",
    "        header.append((\"CRVAL2\", wcs_header[\"CRVAL2\"]))\n",
    "        header.append((\"CTYPE2\", wcs_header[\"CTYPE2\"]))\n",
    "        header.append((\"CUNIT2\", wcs_header[\"CUNIT2\"]))\n",
    "        header.append((\"CDELT3\", wcs_header[\"CDELT3\"]))\n",
    "        header.append((\"CRPIX3\", wcs_header[\"CRPIX3\"]))\n",
    "        header.append((\"CRVAL3\", wcs_header[\"CRVAL3\"]))\n",
    "        header.append((\"CTYPE3\", wcs_header[\"CTYPE3\"]))\n",
    "        header.append((\"CUNIT3\", wcs_header[\"CUNIT3\"]))\n",
    "        header.append((\"CDELT4\", wcs_header[\"CDELT4\"]))\n",
    "        header.append((\"CRPIX4\", wcs_header[\"CRPIX4\"]))\n",
    "        header.append((\"CRVAL4\", wcs_header[\"CRVAL4\"]))\n",
    "        header.append((\"CTYPE4\", wcs_header[\"CTYPE4\"]))\n",
    "        header.append((\"CUNIT4\", \"PAR\"))\n",
    "        header.append((\"EPOCH\", 2000))\n",
    "        # header.append(('BLANK', -32768)) #only for integer data\n",
    "        header.append((\"BSCALE\", 1.0))\n",
    "        header.append((\"BZERO\", 0.0))\n",
    "        datacube_array_units = datacube._array.unit\n",
    "        header.append(\n",
    "            (\"DATAMAX\", np.max(datacube._array.to_value(datacube_array_units)))\n",
    "        )\n",
    "        header.append(\n",
    "            (\"DATAMIN\", np.min(datacube._array.to_value(datacube_array_units)))\n",
    "        )\n",
    "        \n",
    "        # long names break fits format, don't let the user set this\n",
    "        header.append((\"OBJECT\", \"MOCK\"))\n",
    "        header.append((\"BUNIT\", datacube_array_units.to_string(\"fits\")))\n",
    "        header.append((\"MJD-OBS\", Time.now().to_value(\"mjd\")))\n",
    "        header.append((\"BTYPE\", \"Intensity\"))\n",
    "        header.append((\"SPECSYS\", wcs_header[\"SPECSYS\"]))\n",
    "\n",
    "        # flip axes to write\n",
    "        hdu = fits.PrimaryHDU(\n",
    "            header=header, data=datacube._array.to_value(datacube_array_units).T\n",
    "        )\n",
    "        hdu.writeto(filename, overwrite=overwrite)\n",
    "\n",
    "        if channels == \"frequency\":\n",
    "            datacube.velocity_channels()\n",
    "        return\n",
    "\n",
    "def plot_moments(FluxCube, vch, path):\n",
    "    np.seterr(all='ignore')\n",
    "    fig = plt.figure(figsize=(16, 5))\n",
    "    sp1 = fig.add_subplot(1,3,1)\n",
    "    sp2 = fig.add_subplot(1,3,2)\n",
    "    sp3 = fig.add_subplot(1,3,3)\n",
    "    rms = np.std(FluxCube[:16, :16])  # noise in a corner patch where there is little signal\n",
    "    clip = np.where(FluxCube > 5 * rms, 1, 0)\n",
    "    mom0 = np.sum(FluxCube, axis=-1)\n",
    "    mask = np.where(mom0 > .02, 1, np.nan)\n",
    "    mom1 = np.sum(FluxCube * clip * vch, axis=-1) / mom0\n",
    "    mom2 = np.sqrt(np.sum(FluxCube * clip * np.power(vch - mom1[..., np.newaxis], 2), axis=-1)) / mom0\n",
    "    im1 = sp1.imshow(mom0.T, cmap='Greys', aspect=1.0, origin='lower')\n",
    "    plt.colorbar(im1, ax=sp1, label='mom0 [Jy/beam]')\n",
    "    im2 = sp2.imshow((mom1*mask).T, cmap='RdBu', aspect=1.0, origin='lower')\n",
    "    plt.colorbar(im2, ax=sp2, label='mom1 [km/s]')\n",
    "    im3 = sp3.imshow((mom2*mask).T, cmap='magma', aspect=1.0, origin='lower', vmin=0, vmax=300)\n",
    "    plt.colorbar(im3, ax=sp3, label='mom2 [km/s]')\n",
    "    for sp in sp1, sp2, sp3:\n",
    "        sp.set_xlabel('x [px = arcsec/10]')\n",
    "        sp.set_ylabel('y [px = arcsec/10]')\n",
    "    plt.subplots_adjust(wspace=.3)\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: File may have been truncated: actual file length (144841536) is smaller than the expected size (158967360) [astropy.io.fits.file]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 18104832 into shape (128,394,394)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m inFile \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/astro/Documents/casa-data/sims/skymodel_0.fits\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m hdu_list \u001b[39m=\u001b[39m fits\u001b[39m.\u001b[39mopen(inFile, memmap\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m data \u001b[39m=\u001b[39m hdu_list[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdata\n",
      "File \u001b[0;32m~/almasim/lib/python3.8/site-packages/astropy/utils/decorators.py:841\u001b[0m, in \u001b[0;36mlazyproperty.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    839\u001b[0m         val \u001b[39m=\u001b[39m obj_dict\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key, _NotFound)\n\u001b[1;32m    840\u001b[0m         \u001b[39mif\u001b[39;00m val \u001b[39mis\u001b[39;00m _NotFound:\n\u001b[0;32m--> 841\u001b[0m             val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[1;32m    842\u001b[0m             obj_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key] \u001b[39m=\u001b[39m val\n\u001b[1;32m    843\u001b[0m \u001b[39mreturn\u001b[39;00m val\n",
      "File \u001b[0;32m~/almasim/lib/python3.8/site-packages/astropy/io/fits/hdu/image.py:254\u001b[0m, in \u001b[0;36m_ImageBaseHDU.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_axes) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    252\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_scaled_image_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_offset, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_header_scale_info(data\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/almasim/lib/python3.8/site-packages/astropy/io/fits/hdu/image.py:823\u001b[0m, in \u001b[0;36m_ImageBaseHDU._get_scaled_image_data\u001b[0;34m(self, offset, shape)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[39mInternal function for reading image data from a file and apply scale\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39mfactors to it.  Normally this is used for the entire image, but it\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39msupports alternate offset/shape for Section support.\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    821\u001b[0m code \u001b[39m=\u001b[39m BITPIX2DTYPE[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_orig_bitpix]\n\u001b[0;32m--> 823\u001b[0m raw_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_raw_data(shape, code, offset)\n\u001b[1;32m    824\u001b[0m raw_data\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m raw_data\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mnewbyteorder(\u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    826\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_not_scale_image_data \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    827\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_orig_bzero \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_orig_bscale \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blank \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    828\u001b[0m ):\n\u001b[1;32m    829\u001b[0m     \u001b[39m# No further conversion of the data is necessary\u001b[39;00m\n",
      "File \u001b[0;32m~/almasim/lib/python3.8/site-packages/astropy/io/fits/hdu/base.py:549\u001b[0m, in \u001b[0;36m_BaseHDU._get_raw_data\u001b[0;34m(self, shape, code, offset)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mndarray(shape, dtype\u001b[39m=\u001b[39mcode, buffer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer, offset\u001b[39m=\u001b[39moffset)\n\u001b[1;32m    548\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file:\n\u001b[0;32m--> 549\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_file\u001b[39m.\u001b[39;49mreadarray(offset\u001b[39m=\u001b[39;49moffset, dtype\u001b[39m=\u001b[39;49mcode, shape\u001b[39m=\u001b[39;49mshape)\n\u001b[1;32m    550\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/almasim/lib/python3.8/site-packages/astropy/io/fits/file.py:391\u001b[0m, in \u001b[0;36m_File.readarray\u001b[0;34m(self, size, offset, dtype, shape)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file\u001b[39m.\u001b[39mseek(offset)\n\u001b[1;32m    390\u001b[0m         data \u001b[39m=\u001b[39m _array_from_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file, dtype, count)\n\u001b[0;32m--> 391\u001b[0m         data\u001b[39m.\u001b[39;49mshape \u001b[39m=\u001b[39m shape\n\u001b[1;32m    392\u001b[0m         \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m    393\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    394\u001b[0m     \u001b[39m# Make sure we leave the file in the position we found it; on\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     \u001b[39m# some platforms (e.g. Windows) mmaping a file handle can also\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     \u001b[39m# reset its file pointer.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m     \u001b[39m# Also for Windows when using mmap seek() may return weird\u001b[39;00m\n\u001b[1;32m    398\u001b[0m     \u001b[39m# negative values, which is fixed by calling tell() before.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 18104832 into shape (128,394,394)"
     ]
    }
   ],
   "source": [
    "\n",
    "inFile = '/home/astro/Documents/casa-data/sims/skymodel_0.fits'\n",
    "hdu_list = fits.open(inFile, memmap=False)\n",
    "data = hdu_list[0].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging diffuse sources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casa6.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
